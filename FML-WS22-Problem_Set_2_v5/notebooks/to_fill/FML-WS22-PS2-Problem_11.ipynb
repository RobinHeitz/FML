{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "486faa51eccb2b8ba0e99ed360f8268b",
     "grade": false,
     "grade_id": "cell-646c0005438fc458",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Fundamentals of Machine Learning - WS 22\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS2#11 - Lasso Regularization\n",
    "\n",
    "The goal of this notebook is to illustrate Lasso regularization, and to highlight its differences with Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple polynomial regression problem where we want to fit the following function $f(x) = x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we do not have access to $f$, but only to noisy samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "X_plot = np.linspace(-2, 2, 1001)\n",
    "X = np.random.uniform(-2, 2, N)\n",
    "Y = f(X) + np.random.normal(0, 0.2, size=N)\n",
    "plt.scatter(X, Y, label='data')\n",
    "plt.plot(X_plot, f(X_plot), label='f', color='red')\n",
    "plt.legend(loc='best')\n",
    "_=plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform polynomial linear regression. We begin by computing the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, M):\n",
    "    return np.vstack([\n",
    "        X**k for k in range(M+1)\n",
    "    ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 8\n",
    "features = polynomial_features(X, M)\n",
    "plot_features = polynomial_features(X_plot, M)\n",
    "print(features.shape, plot_features.shape)\n",
    "\n",
    "# fit_intercept controls whether the LinearRegression adds a bias term\n",
    "# We don't need one, since it's already in our features\n",
    "unregularized = sklearn.linear_model.LinearRegression(fit_intercept=False)  \n",
    "ridge = sklearn.linear_model.Ridge(fit_intercept=False, alpha = 5)\n",
    "lasso = sklearn.linear_model.Lasso(fit_intercept=False, alpha = 0.01, max_iter=100000)\n",
    "models = {'Unregularized': unregularized, 'Ridge': ridge, 'Lasso': lasso}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(features, Y)\n",
    "    plt.plot(X_plot, model.predict(plot_features).squeeze(), label=name)\n",
    "plt.plot(X_plot, f(X_plot), label='f', color='red')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the magnitude of the weigths for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({n:m.coef_ for n,m in models.items()})\n",
    "np.abs(df).plot.bar(logy=True)\n",
    "plt.ylabel('Weight magnitude')\n",
    "_=plt.xlabel('Feature degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the value of the weights of Lasso regularization evolve as the regularizer increases, and compare this to Ridge regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers = np.array([10**k for k in np.linspace(-3, 0, 100)])\n",
    "weights_lasso = np.zeros((regularizers.shape[0], M+1))\n",
    "weights_ridge = np.zeros((regularizers.shape[0], M+1))\n",
    "\n",
    "for n, reg in enumerate(regularizers):\n",
    "    mdl_lasso = sklearn.linear_model.Lasso(alpha=reg, max_iter=100000)\n",
    "    mdl_lasso.fit(features, Y)\n",
    "    weights_lasso[n, :] = mdl_lasso.coef_\n",
    "    mdl_ridge = sklearn.linear_model.Ridge(alpha=reg)\n",
    "    mdl_ridge.fit(features, Y)\n",
    "    weights_ridge[n, :] = mdl_ridge.coef_\n",
    "\n",
    "labels = [f'$x^{m}$ (Lasso)' for m in range(M+1)] + [f'$x^{m}$ (Ridge)' for m in range(M+1)]\n",
    "ridge_start_index = M+1\n",
    "m=6\n",
    "df = pd.DataFrame(data=np.hstack((weights_lasso, weights_ridge)), columns=labels, index=pd.Series(regularizers))\n",
    "_=np.abs(df.loc[:, [labels[m], labels[ridge_start_index + m]]]).plot(logx=True)\n",
    "plt.xlabel('Regularization')\n",
    "_=plt.ylabel('Weight magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso performs **feature selection**; the model it outputs is sparse.\n",
    "\n",
    "However, it is not ideal: as we see below, for large values of the regularization coefficient, Lasso does not know which odd power of $x$ to use for prediction.\n",
    "In general, Lasso is not very robust against correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(df.loc[:, labels[ridge_start_index:]]).plot(logx=True)\n",
    "plt.title('Weights magnitude (Ridge)')\n",
    "plt.xlabel('Regularization')\n",
    "_=plt.ylabel('Weight magnitude')\n",
    "np.abs(df.loc[:, labels[:ridge_start_index]]).plot(logx=True)\n",
    "_=plt.title('Weights magnitude (Lasso)')\n",
    "plt.xlabel('Regularization')\n",
    "_=plt.ylabel('Weight magnitude')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (v3.9.7:1016ef3790, Aug 30 2021, 16:25:35) \n[Clang 12.0.5 (clang-1205.0.22.11)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d10a3f09137c9e8034640796eb99bd80853bcc4056b85740b3fc3fb32f9e791"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
